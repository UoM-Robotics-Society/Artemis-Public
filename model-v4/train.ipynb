{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install and import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydot in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.0.2)\n",
      "Requirement already satisfied: pyparsing>=3.0.9 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydot) (3.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.18.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (72.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.12.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.67.1)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.13.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2024.6.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (2.0.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\simpl\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install pydot\n",
    "%pip install tensorflow\n",
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from constants import (\n",
    "    DATA_INPUT_PATH,\n",
    "    MODEL_PATH,\n",
    "    METADATA_PATH,\n",
    ")\n",
    "\n",
    "CLASSES = {\n",
    "    0: \"resting\",\n",
    "    1: \"palm up\",\n",
    "    2: \"closed fist\",\n",
    "    3: \"ok\",\n",
    "    4: \"pointer finger\",\n",
    "    5: \"peace\",\n",
    "    6: \"shaa\",\n",
    "    7: \"peace among worlds\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the files in the data dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WindowsPath('data/emg_gestures_data_20250128_220435.csv'), WindowsPath('data/emg_gestures_data_20250201_215436.csv'), WindowsPath('data/emg_gestures_data_20250202_172502.csv'), WindowsPath('data/emg_gestures_data_20250205_184712.csv'), WindowsPath('data/emg_gestures_data_20250205_212859.csv'), WindowsPath('data/emg_gestures_data_20250219_122322.csv'), WindowsPath('data/emg_gestures_data_20250226_122030.csv')]\n"
     ]
    }
   ],
   "source": [
    "# Read all of the files in the data folder\n",
    "files_in_folder = Path(DATA_INPUT_PATH).glob(\"*.csv\")\n",
    "\n",
    "files = [x for x in files_in_folder]\n",
    "print([file for file in files])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert .csv(s) to dataframes and concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   gesture_id   s1   s2   s3   s4   s5   s6   s7  s8\n",
      "0           0  183  264  188  118  119  115  178  94\n",
      "1           0   91  203  149   71   60   66   86  49\n",
      "2           0   73  229  158   80   53   48   69  40\n",
      "3           0   60  230  154   76   45   43   55  35\n",
      "4           0   53  264  204   81   41   37   47  32\n",
      "Shape of dataframe before removing duplicates (117348, 9)\n",
      "Shape of dataframe after removing duplicates (117348, 9)\n"
     ]
    }
   ],
   "source": [
    "# Read the data from the files\n",
    "dfs = []\n",
    "\n",
    "for file in files:\n",
    "    df = pd.read_csv(str(file))\n",
    "    dfs.append(df)\n",
    "        \n",
    "# Convert the data to a DataFrame\n",
    "df = pd.concat([x for x in dfs], axis=0)\n",
    "\n",
    "columns = [\"gesture_id\", \"s1\", \"s2\", \"s3\", \"s4\", \"s5\", \"s6\", \"s7\", \"s8\"]\n",
    "df = df[columns]\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "# Before removing duplicates\n",
    "print(f\"Shape of dataframe before removing duplicates {df.shape}\")\n",
    "# Remove duplicates\n",
    "df = df.drop_duplicates()\n",
    "print(f\"Shape of dataframe after removing duplicates {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(117348, 9)\n",
      "   gesture_id         s1          s2          s3         s4         s5  \\\n",
      "0         0.0  57.869681   83.484130   59.450820  37.314876  37.631104   \n",
      "1         0.0  64.629715  105.311443   75.858421  43.548823  42.143801   \n",
      "2         0.0  68.628711  127.806886   90.834465  50.363677  45.354162   \n",
      "3         0.0  71.203230  147.053052  103.065513  55.804122  47.534198   \n",
      "4         0.0  73.149163  169.098196  121.589884  61.401954  49.270681   \n",
      "\n",
      "          s6         s7         s8  \n",
      "0  36.366193  56.288542  29.725410  \n",
      "1  41.929703  62.513998  33.521635  \n",
      "2  44.592600  66.212537  35.828759  \n",
      "3  46.619738  68.458747  37.499333  \n",
      "4  48.065580  70.053551  38.840700  \n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "window_size = 10  # Number of past samples to include\n",
    "\n",
    "# Extract feature columns (excluding label, if it exists)\n",
    "feature_columns = [col for col in df.columns if col != 'Label']\n",
    "features = df[feature_columns].to_numpy()\n",
    "\n",
    "# Convert features into a 3D array: [samples, features, time]\n",
    "n_samples = len(features)\n",
    "n_features = len(feature_columns)\n",
    "reshaped_data = []\n",
    "\n",
    "for i in range(n_samples):\n",
    "    # Get the last `window_size` rows or fewer for each sample\n",
    "    window = features[max(i - window_size + 1, 0):i + 1]\n",
    "    \n",
    "    # Pad the window if it has fewer than `window_size` rows\n",
    "    if len(window) < window_size:\n",
    "        padding = np.zeros((window_size - len(window), n_features))\n",
    "        window = np.vstack((padding, window))\n",
    "    \n",
    "    reshaped_data.append(window)\n",
    "\n",
    "# Convert list to 3D numpy array\n",
    "reshaped_data = np.stack(reshaped_data, axis=0)\n",
    "reshaped_data = reshaped_data.transpose(0, 2, 1)\n",
    "df[feature_columns] = np.sqrt(np.mean(np.square(reshaped_data), axis=2))\n",
    "    \n",
    "print(df.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale and clean the data, then train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\simpl\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1174/1174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8303 - loss: 0.5409 - val_accuracy: 0.9723 - val_loss: 0.0976\n",
      "Epoch 2/100\n",
      "\u001b[1m1174/1174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9514 - loss: 0.1608 - val_accuracy: 0.9782 - val_loss: 0.0810\n",
      "Epoch 3/100\n",
      "\u001b[1m1174/1174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9617 - loss: 0.1271 - val_accuracy: 0.9802 - val_loss: 0.0718\n",
      "Epoch 4/100\n",
      "\u001b[1m1174/1174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9654 - loss: 0.1190 - val_accuracy: 0.9820 - val_loss: 0.0655\n",
      "Epoch 5/100\n",
      "\u001b[1m1174/1174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9684 - loss: 0.1094 - val_accuracy: 0.9834 - val_loss: 0.0577\n",
      "Epoch 6/100\n",
      "\u001b[1m1174/1174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9709 - loss: 0.0996 - val_accuracy: 0.9846 - val_loss: 0.0563\n",
      "Epoch 7/100\n",
      "\u001b[1m1174/1174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9701 - loss: 0.0999 - val_accuracy: 0.9851 - val_loss: 0.0524\n",
      "Epoch 8/100\n",
      "\u001b[1m1174/1174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9717 - loss: 0.0939 - val_accuracy: 0.9856 - val_loss: 0.0511\n",
      "Epoch 9/100\n",
      "\u001b[1m1174/1174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9738 - loss: 0.0900 - val_accuracy: 0.9848 - val_loss: 0.0532\n",
      "Epoch 10/100\n",
      "\u001b[1m1174/1174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9745 - loss: 0.0864 - val_accuracy: 0.9868 - val_loss: 0.0487\n",
      "Epoch 11/100\n",
      "\u001b[1m1174/1174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9739 - loss: 0.0867 - val_accuracy: 0.9871 - val_loss: 0.0465\n",
      "Epoch 12/100\n",
      "\u001b[1m1174/1174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9744 - loss: 0.0863 - val_accuracy: 0.9859 - val_loss: 0.0464\n",
      "Epoch 13/100\n",
      "\u001b[1m1174/1174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9752 - loss: 0.0811 - val_accuracy: 0.9859 - val_loss: 0.0495\n",
      "Epoch 14/100\n",
      "\u001b[1m1174/1174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9765 - loss: 0.0801 - val_accuracy: 0.9883 - val_loss: 0.0434\n",
      "Epoch 15/100\n",
      "\u001b[1m1174/1174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9762 - loss: 0.0805 - val_accuracy: 0.9873 - val_loss: 0.0447\n",
      "Epoch 16/100\n",
      "\u001b[1m1174/1174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9767 - loss: 0.0779 - val_accuracy: 0.9879 - val_loss: 0.0433\n",
      "Epoch 17/100\n",
      "\u001b[1m1174/1174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9775 - loss: 0.0768 - val_accuracy: 0.9870 - val_loss: 0.0441\n",
      "Epoch 18/100\n",
      "\u001b[1m1174/1174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9762 - loss: 0.0796 - val_accuracy: 0.9886 - val_loss: 0.0418\n",
      "Epoch 19/100\n",
      "\u001b[1m1174/1174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9784 - loss: 0.0766 - val_accuracy: 0.9893 - val_loss: 0.0387\n",
      "Epoch 20/100\n",
      "\u001b[1m 369/1174\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9797 - loss: 0.0685"
     ]
    }
   ],
   "source": [
    "X = df.drop(columns=['gesture_id'])\n",
    "y = df['gesture_id']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Reshape the data for Conv1D\n",
    "X_train_scaled = X_train_scaled.reshape(X_train_scaled.shape[0], X_train_scaled.shape[1], 1)\n",
    "X_test_scaled = X_test_scaled.reshape(X_test_scaled.shape[0], X_test_scaled.shape[1], 1)\n",
    "\n",
    "# # filter for valid classes because the data is not clean\n",
    "# valid_classes = [0, 2, 3]\n",
    "# mask_train = y_train.isin(valid_classes)\n",
    "# mask_test = y_test.isin(valid_classes)\n",
    "\n",
    "# # apply the mask to the training and testing data\n",
    "# X_train_filtered = X_train_scaled[mask_train]\n",
    "# y_train_filtered = y_train[mask_train]\n",
    "\n",
    "# X_test_filtered = X_test_scaled[mask_test]\n",
    "# y_test_filtered = y_test[mask_test]\n",
    "\n",
    "# one hot encode the target data\n",
    "y_train_categorical = to_categorical(y_train, num_classes=8)\n",
    "y_test_categorical = to_categorical(y_test, num_classes=8)\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(8, activation='softmax')\n",
    "])\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Compile the model with categorical crossentropy for multi-class classification\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001), \n",
    "    loss='categorical_crossentropy', \n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "# Train the model using the filtered training data\n",
    "model.fit(\n",
    "    X_train_scaled, \n",
    "    y_train_categorical, \n",
    "    epochs=100, \n",
    "    batch_size=64, \n",
    "    validation_split=0.2, \n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Evaluate the model on the filtered test set\n",
    "test_loss, test_acc = model.evaluate(X_test_scaled, y_test_categorical)\n",
    "\n",
    "print(f\"Test accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "model.save(f\"model/{MODEL_PATH}\")\n",
    "\n",
    "# Save the scaler and the column names to a pickle file\n",
    "with open(f\"model/{METADATA_PATH}\", 'wb') as f:\n",
    "    pickle.dump((scaler, X_train.columns), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step\n",
      "Predicted class: 2 - closed fist\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Predicted class: 7 - peace among worlds\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Predicted class: 7 - peace among worlds\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Predicted class: 2 - closed fist\n"
     ]
    }
   ],
   "source": [
    "# thumbs-up then peace-sign\n",
    "emg_data = [\n",
    "    [160,245,126,32,28,25,26,99], # thumbs-up\n",
    "    [67,197,559,104,41,82,257,169], # peace-sign\n",
    "    [205,440,165,40,27,83,229,226], # gun-fingers\n",
    "    [416,434,134,71,36,48,102,103] # fist\n",
    "]\n",
    "\n",
    "for data in emg_data:\n",
    "    emg_features_df = pd.DataFrame([data], columns=X_train.columns)\n",
    "\n",
    "    emg_features_scaled = scaler.transform(emg_features_df)\n",
    "    emg_features_reshaped = emg_features_scaled.reshape(1, -1)\n",
    "\n",
    "    prediction = model.predict(emg_features_reshaped)\n",
    "    predicted_class = np.argmax(prediction)\n",
    "\n",
    "    print(f\"Predicted class: {predicted_class} - {CLASSES[predicted_class]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
